{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(os.path.join('train.csv'))\n",
    "test = pd.read_csv(os.path.join('test.csv'))\n",
    "ss = pd.read_csv(os.path.join('Sample_submission.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obj_cols = [i for i in train.columns if train[i].dtype == np.object]\n",
    "np.size(obj_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "\n",
    "for i in train.columns:\n",
    "    if train[i].dtype == np.object:\n",
    "        train[i] = le.fit_transform(train[i])\n",
    "        test[i] = le.transform(test[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train.drop(['Id', 'Attrition', 'Behaviour'], axis=1)\n",
    "y_train = train.Attrition\n",
    "X_test = test.drop(['Id', 'Behaviour'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier as DTC\n",
    "from sklearn.ensemble import RandomForestClassifier as RFC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic = linear_model.LogisticRegression()\n",
    "ridge = linear_model.Ridge()\n",
    "lasso = linear_model.Lasso()\n",
    "lasso_lars = linear_model.LassoLars()\n",
    "elastic = linear_model.ElasticNet()\n",
    "bayesian_ridge = linear_model.BayesianRidge()\n",
    "sgd = linear_model.SGDClassifier()\n",
    "decisontree = DTC()\n",
    "randomforest = RFC()\n",
    "sv = SVC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [ridge, lasso, lasso_lars, elastic, bayesian_ridge, logistic, sgd, decisontree, randomforest, sv]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score as roc_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None,\n",
      "      normalize=False, random_state=None, solver='auto', tol=0.001)\n",
      "Lasso(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000,\n",
      "      normalize=False, positive=False, precompute=False, random_state=None,\n",
      "      selection='cyclic', tol=0.0001, warm_start=False)\n",
      "LassoLars(alpha=1.0, copy_X=True, eps=2.220446049250313e-16, fit_intercept=True,\n",
      "          fit_path=True, max_iter=500, normalize=True, positive=False,\n",
      "          precompute='auto', verbose=False)\n",
      "ElasticNet(alpha=1.0, copy_X=True, fit_intercept=True, l1_ratio=0.5,\n",
      "           max_iter=1000, normalize=False, positive=False, precompute=False,\n",
      "           random_state=None, selection='cyclic', tol=0.0001, warm_start=False)\n",
      "BayesianRidge(alpha_1=1e-06, alpha_2=1e-06, alpha_init=None,\n",
      "              compute_score=False, copy_X=True, fit_intercept=True,\n",
      "              lambda_1=1e-06, lambda_2=1e-06, lambda_init=None, n_iter=300,\n",
      "              normalize=False, tol=0.001, verbose=False)\n",
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
      "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
      "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
      "                   warm_start=False)\n",
      "CV_mean:  0.847645923405355\n",
      "std: 0.0038140467325050113\n",
      "\n",
      "\n",
      "SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n",
      "              early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
      "              l1_ratio=0.15, learning_rate='optimal', loss='hinge',\n",
      "              max_iter=1000, n_iter_no_change=5, n_jobs=None, penalty='l2',\n",
      "              power_t=0.5, random_state=None, shuffle=True, tol=0.001,\n",
      "              validation_fraction=0.1, verbose=0, warm_start=False)\n",
      "CV_mean:  0.8038106634505459\n",
      "std: 0.022581217258717135\n",
      "\n",
      "\n",
      "DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=None, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best')\n",
      "CV_mean:  0.9359537897999436\n",
      "std: 0.01028964840514494\n",
      "\n",
      "\n",
      "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
      "                       criterion='gini', max_depth=None, max_features='auto',\n",
      "                       max_leaf_nodes=None, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False)\n",
      "CV_mean:  1.0\n",
      "std: 0.0\n",
      "\n",
      "\n",
      "SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='rbf',\n",
      "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "    tol=0.001, verbose=False)\n",
      "CV_mean:  0.9781252187303142\n",
      "std: 0.0045951909125380155\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def get_cv_scores(model):\n",
    "    scores = cross_val_score(model, X_train, y_train, scoring='roc_auc', cv=5)\n",
    "    print('CV_mean: ', np.mean(scores))\n",
    "    print('std:', np.std(scores))\n",
    "    print('\\n')\n",
    "    \n",
    "for model in models:\n",
    "    print(model)\n",
    "    try: \n",
    "        get_cv_scores(model)\n",
    "    except ValueError:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV as GCV\n",
    "from sklearn.model_selection import RandomizedSearchCV as RCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 480 candidates, totalling 2400 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 312 tasks      | elapsed:    0.9s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score:  0.8489452487737642\n",
      "Best Parameters:  {'C': 0.1, 'class_weight': {1: 0.3, 0: 0.7}, 'penalty': 'l2', 'random_state': None, 'solver': 'saga'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 2400 out of 2400 | elapsed:   10.2s finished\n"
     ]
    }
   ],
   "source": [
    "penalty = ['l1', 'l2']\n",
    "C = [0.0001, 0.001, 0.01, 0.1, 1, 10, 100, 1000]\n",
    "solver = ['lbfgs', 'liblinear', 'saga']\n",
    "class_weight = [{1:0.5, 0:0.5}, {1:0.6, 0:0.4}, {1:0.4, 0:0.6}, {1:0.7, 0:0.3}, {1:0.3, 0:0.7}]\n",
    "random_state=[None, 1]\n",
    "\n",
    "params_grid = dict(penalty=penalty,\n",
    "                   C=C,\n",
    "                   class_weight=class_weight,\n",
    "                   solver=solver,\n",
    "                   random_state=random_state)\n",
    "\n",
    "grid = GCV(estimator=logistic, param_grid=params_grid, scoring='roc_auc', cv=5, n_jobs=-1, verbose=1 )\n",
    "\n",
    "grid_result = grid.fit(X_train, y_train)\n",
    "print('Best Score: ', grid_result.best_score_)\n",
    "print('Best Parameters: ', grid_result.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.87718253, 0.12281747],\n",
       "       [0.94478339, 0.05521661],\n",
       "       [0.58916714, 0.41083286],\n",
       "       [0.60075249, 0.39924751],\n",
       "       [0.96916741, 0.03083259],\n",
       "       [0.93800466, 0.06199534],\n",
       "       [0.62145701, 0.37854299],\n",
       "       [0.88677403, 0.11322597],\n",
       "       [0.61863481, 0.38136519],\n",
       "       [0.95591263, 0.04408737],\n",
       "       [0.99027868, 0.00972132],\n",
       "       [0.60937388, 0.39062612],\n",
       "       [0.96026398, 0.03973602],\n",
       "       [0.88530862, 0.11469138],\n",
       "       [0.94856766, 0.05143234],\n",
       "       [0.73885956, 0.26114044],\n",
       "       [0.62972823, 0.37027177],\n",
       "       [0.48729206, 0.51270794],\n",
       "       [0.91113482, 0.08886518],\n",
       "       [0.97645714, 0.02354286],\n",
       "       [0.96863893, 0.03136107],\n",
       "       [0.08720153, 0.91279847],\n",
       "       [0.93025653, 0.06974347],\n",
       "       [0.93129193, 0.06870807],\n",
       "       [0.86531343, 0.13468657],\n",
       "       [0.94835821, 0.05164179],\n",
       "       [0.92191015, 0.07808985],\n",
       "       [0.94116089, 0.05883911],\n",
       "       [0.22904442, 0.77095558],\n",
       "       [0.7418335 , 0.2581665 ],\n",
       "       [0.92557239, 0.07442761],\n",
       "       [0.66924762, 0.33075238],\n",
       "       [0.67157343, 0.32842657],\n",
       "       [0.43824895, 0.56175105],\n",
       "       [0.98317645, 0.01682355],\n",
       "       [0.96224959, 0.03775041],\n",
       "       [0.94262453, 0.05737547],\n",
       "       [0.98804935, 0.01195065],\n",
       "       [0.49940091, 0.50059909],\n",
       "       [0.41579669, 0.58420331],\n",
       "       [0.08729792, 0.91270208],\n",
       "       [0.48124923, 0.51875077],\n",
       "       [0.97626258, 0.02373742],\n",
       "       [0.93415595, 0.06584405],\n",
       "       [0.99503965, 0.00496035],\n",
       "       [0.76379957, 0.23620043],\n",
       "       [0.89769247, 0.10230753],\n",
       "       [0.93048573, 0.06951427],\n",
       "       [0.9987901 , 0.0012099 ],\n",
       "       [0.60373324, 0.39626676],\n",
       "       [0.80936723, 0.19063277],\n",
       "       [0.909907  , 0.090093  ],\n",
       "       [0.46375593, 0.53624407],\n",
       "       [0.47323778, 0.52676222],\n",
       "       [0.28728847, 0.71271153],\n",
       "       [0.43765366, 0.56234634],\n",
       "       [0.91246582, 0.08753418],\n",
       "       [0.12887481, 0.87112519],\n",
       "       [0.99097841, 0.00902159],\n",
       "       [0.92431404, 0.07568596],\n",
       "       [0.92227246, 0.07772754],\n",
       "       [0.79222393, 0.20777607],\n",
       "       [0.35663401, 0.64336599],\n",
       "       [0.97670999, 0.02329001],\n",
       "       [0.62205206, 0.37794794],\n",
       "       [0.91838854, 0.08161146],\n",
       "       [0.87460187, 0.12539813],\n",
       "       [0.54587463, 0.45412537],\n",
       "       [0.67406411, 0.32593589],\n",
       "       [0.74753732, 0.25246268],\n",
       "       [0.7088585 , 0.2911415 ],\n",
       "       [0.96667076, 0.03332924],\n",
       "       [0.57578697, 0.42421303],\n",
       "       [0.48599346, 0.51400654],\n",
       "       [0.52949475, 0.47050525],\n",
       "       [0.10771448, 0.89228552],\n",
       "       [0.92373181, 0.07626819],\n",
       "       [0.75450726, 0.24549274],\n",
       "       [0.70229964, 0.29770036],\n",
       "       [0.69948772, 0.30051228],\n",
       "       [0.92950596, 0.07049404],\n",
       "       [0.72943312, 0.27056688],\n",
       "       [0.56365778, 0.43634222],\n",
       "       [0.99892539, 0.00107461],\n",
       "       [0.77317285, 0.22682715],\n",
       "       [0.9580097 , 0.0419903 ],\n",
       "       [0.37178463, 0.62821537],\n",
       "       [0.4953633 , 0.5046367 ],\n",
       "       [0.81628703, 0.18371297],\n",
       "       [0.79992146, 0.20007854],\n",
       "       [0.39894433, 0.60105567],\n",
       "       [0.9429839 , 0.0570161 ],\n",
       "       [0.69001603, 0.30998397],\n",
       "       [0.87966651, 0.12033349],\n",
       "       [0.12459828, 0.87540172],\n",
       "       [0.41659176, 0.58340824],\n",
       "       [0.49761375, 0.50238625],\n",
       "       [0.94992952, 0.05007048],\n",
       "       [0.98370342, 0.01629658],\n",
       "       [0.92162349, 0.07837651],\n",
       "       [0.84403238, 0.15596762],\n",
       "       [0.89814073, 0.10185927],\n",
       "       [0.88172564, 0.11827436],\n",
       "       [0.94540164, 0.05459836],\n",
       "       [0.72821799, 0.27178201],\n",
       "       [0.82039495, 0.17960505],\n",
       "       [0.84056357, 0.15943643],\n",
       "       [0.64091057, 0.35908943],\n",
       "       [0.91404976, 0.08595024],\n",
       "       [0.99006424, 0.00993576],\n",
       "       [0.64642267, 0.35357733],\n",
       "       [0.4878445 , 0.5121555 ],\n",
       "       [0.76902357, 0.23097643],\n",
       "       [0.96328189, 0.03671811],\n",
       "       [0.83545611, 0.16454389],\n",
       "       [0.95224907, 0.04775093],\n",
       "       [0.9668839 , 0.0331161 ],\n",
       "       [0.96950779, 0.03049221],\n",
       "       [0.67006387, 0.32993613],\n",
       "       [0.88283816, 0.11716184],\n",
       "       [0.44015784, 0.55984216],\n",
       "       [0.82841443, 0.17158557],\n",
       "       [0.87435591, 0.12564409],\n",
       "       [0.44408785, 0.55591215],\n",
       "       [0.2736979 , 0.7263021 ],\n",
       "       [0.95685161, 0.04314839],\n",
       "       [0.85750396, 0.14249604],\n",
       "       [0.39467758, 0.60532242],\n",
       "       [0.42329511, 0.57670489],\n",
       "       [0.91984277, 0.08015723],\n",
       "       [0.63411793, 0.36588207],\n",
       "       [0.97759093, 0.02240907],\n",
       "       [0.95105604, 0.04894396],\n",
       "       [0.48572483, 0.51427517],\n",
       "       [0.97037932, 0.02962068],\n",
       "       [0.91490002, 0.08509998],\n",
       "       [0.05128666, 0.94871334],\n",
       "       [0.87178581, 0.12821419],\n",
       "       [0.35968145, 0.64031855],\n",
       "       [0.99167797, 0.00832203],\n",
       "       [0.83350595, 0.16649405],\n",
       "       [0.64468671, 0.35531329],\n",
       "       [0.87144736, 0.12855264],\n",
       "       [0.89692585, 0.10307415],\n",
       "       [0.71061029, 0.28938971],\n",
       "       [0.56003863, 0.43996137],\n",
       "       [0.63390032, 0.36609968],\n",
       "       [0.43760088, 0.56239912],\n",
       "       [0.87349481, 0.12650519],\n",
       "       [0.31956249, 0.68043751],\n",
       "       [0.29760688, 0.70239312],\n",
       "       [0.37508075, 0.62491925],\n",
       "       [0.98315763, 0.01684237],\n",
       "       [0.24690453, 0.75309547],\n",
       "       [0.87793102, 0.12206898],\n",
       "       [0.88120719, 0.11879281],\n",
       "       [0.93669381, 0.06330619],\n",
       "       [0.87469131, 0.12530869],\n",
       "       [0.88284287, 0.11715713],\n",
       "       [0.97273588, 0.02726412],\n",
       "       [0.1276945 , 0.8723055 ],\n",
       "       [0.70625549, 0.29374451],\n",
       "       [0.80786702, 0.19213298],\n",
       "       [0.98095413, 0.01904587],\n",
       "       [0.8014959 , 0.1985041 ],\n",
       "       [0.51862972, 0.48137028],\n",
       "       [0.60659487, 0.39340513],\n",
       "       [0.48324306, 0.51675694],\n",
       "       [0.97676154, 0.02323846],\n",
       "       [0.83680509, 0.16319491],\n",
       "       [0.92140648, 0.07859352],\n",
       "       [0.96967365, 0.03032635],\n",
       "       [0.52182369, 0.47817631],\n",
       "       [0.13498714, 0.86501286],\n",
       "       [0.97866204, 0.02133796],\n",
       "       [0.66789933, 0.33210067],\n",
       "       [0.81526051, 0.18473949],\n",
       "       [0.82463362, 0.17536638],\n",
       "       [0.93365002, 0.06634998],\n",
       "       [0.25687901, 0.74312099],\n",
       "       [0.4844439 , 0.5155561 ],\n",
       "       [0.5069959 , 0.4930041 ],\n",
       "       [0.31830753, 0.68169247],\n",
       "       [0.91222606, 0.08777394],\n",
       "       [0.08533731, 0.91466269],\n",
       "       [0.89760285, 0.10239715],\n",
       "       [0.98600761, 0.01399239],\n",
       "       [0.82019694, 0.17980306],\n",
       "       [0.97606064, 0.02393936],\n",
       "       [0.83147007, 0.16852993],\n",
       "       [0.65490339, 0.34509661],\n",
       "       [0.85825883, 0.14174117],\n",
       "       [0.98118205, 0.01881795],\n",
       "       [0.56184218, 0.43815782],\n",
       "       [0.15618525, 0.84381475],\n",
       "       [0.34363414, 0.65636586],\n",
       "       [0.66991854, 0.33008146],\n",
       "       [0.75386015, 0.24613985],\n",
       "       [0.95942074, 0.04057926],\n",
       "       [0.63042305, 0.36957695],\n",
       "       [0.76865104, 0.23134896],\n",
       "       [0.29465368, 0.70534632],\n",
       "       [0.10703134, 0.89296866],\n",
       "       [0.95211607, 0.04788393],\n",
       "       [0.64326606, 0.35673394],\n",
       "       [0.96335873, 0.03664127],\n",
       "       [0.14983602, 0.85016398],\n",
       "       [0.70183582, 0.29816418],\n",
       "       [0.6679715 , 0.3320285 ],\n",
       "       [0.50177765, 0.49822235],\n",
       "       [0.20893494, 0.79106506],\n",
       "       [0.7947428 , 0.2052572 ],\n",
       "       [0.94008437, 0.05991563],\n",
       "       [0.62114957, 0.37885043],\n",
       "       [0.12878259, 0.87121741],\n",
       "       [0.27628734, 0.72371266],\n",
       "       [0.20290511, 0.79709489],\n",
       "       [0.83020517, 0.16979483],\n",
       "       [0.61483046, 0.38516954],\n",
       "       [0.94454164, 0.05545836],\n",
       "       [0.66225135, 0.33774865],\n",
       "       [0.82162885, 0.17837115],\n",
       "       [0.60243562, 0.39756438],\n",
       "       [0.52065659, 0.47934341],\n",
       "       [0.49202295, 0.50797705],\n",
       "       [0.94724979, 0.05275021],\n",
       "       [0.40850813, 0.59149187],\n",
       "       [0.71037034, 0.28962966],\n",
       "       [0.87788992, 0.12211008],\n",
       "       [0.82953705, 0.17046295],\n",
       "       [0.14103573, 0.85896427],\n",
       "       [0.85108406, 0.14891594],\n",
       "       [0.54148666, 0.45851334],\n",
       "       [0.59441343, 0.40558657],\n",
       "       [0.95156337, 0.04843663],\n",
       "       [0.9494442 , 0.0505558 ],\n",
       "       [0.87938377, 0.12061623],\n",
       "       [0.95335821, 0.04664179],\n",
       "       [0.12153096, 0.87846904],\n",
       "       [0.581125  , 0.418875  ],\n",
       "       [0.96296619, 0.03703381],\n",
       "       [0.92960809, 0.07039191],\n",
       "       [0.42705884, 0.57294116],\n",
       "       [0.34112115, 0.65887885],\n",
       "       [0.91764111, 0.08235889],\n",
       "       [0.99169327, 0.00830673],\n",
       "       [0.18068739, 0.81931261],\n",
       "       [0.81245434, 0.18754566],\n",
       "       [0.99211394, 0.00788606],\n",
       "       [0.95779072, 0.04220928],\n",
       "       [0.85316161, 0.14683839],\n",
       "       [0.9761574 , 0.0238426 ],\n",
       "       [0.94626775, 0.05373225],\n",
       "       [0.9480251 , 0.0519749 ],\n",
       "       [0.77541774, 0.22458226],\n",
       "       [0.1182643 , 0.8817357 ],\n",
       "       [0.9355243 , 0.0644757 ],\n",
       "       [0.794926  , 0.205074  ],\n",
       "       [0.4412857 , 0.5587143 ],\n",
       "       [0.51090702, 0.48909298],\n",
       "       [0.91608456, 0.08391544],\n",
       "       [0.64325015, 0.35674985],\n",
       "       [0.47246959, 0.52753041],\n",
       "       [0.24100289, 0.75899711],\n",
       "       [0.402294  , 0.597706  ],\n",
       "       [0.45084236, 0.54915764],\n",
       "       [0.90080626, 0.09919374],\n",
       "       [0.92515094, 0.07484906],\n",
       "       [0.24481711, 0.75518289],\n",
       "       [0.95769045, 0.04230955],\n",
       "       [0.91760127, 0.08239873],\n",
       "       [0.23147056, 0.76852944],\n",
       "       [0.0119671 , 0.9880329 ],\n",
       "       [0.51219679, 0.48780321],\n",
       "       [0.15610323, 0.84389677],\n",
       "       [0.75189647, 0.24810353],\n",
       "       [0.74932493, 0.25067507],\n",
       "       [0.78974532, 0.21025468],\n",
       "       [0.84279547, 0.15720453],\n",
       "       [0.9187286 , 0.0812714 ],\n",
       "       [0.70325838, 0.29674162],\n",
       "       [0.40215982, 0.59784018],\n",
       "       [0.91601754, 0.08398246],\n",
       "       [0.9605496 , 0.0394504 ],\n",
       "       [0.674516  , 0.325484  ],\n",
       "       [0.09717996, 0.90282004],\n",
       "       [0.63619272, 0.36380728],\n",
       "       [0.70549041, 0.29450959],\n",
       "       [0.88933769, 0.11066231],\n",
       "       [0.82587229, 0.17412771],\n",
       "       [0.24575267, 0.75424733],\n",
       "       [0.6406486 , 0.3593514 ],\n",
       "       [0.86397799, 0.13602201],\n",
       "       [0.64054064, 0.35945936],\n",
       "       [0.96345295, 0.03654705],\n",
       "       [0.60741154, 0.39258846],\n",
       "       [0.82502237, 0.17497763],\n",
       "       [0.87550746, 0.12449254],\n",
       "       [0.49066759, 0.50933241],\n",
       "       [0.82323104, 0.17676896],\n",
       "       [0.84278774, 0.15721226],\n",
       "       [0.96233475, 0.03766525],\n",
       "       [0.84829924, 0.15170076],\n",
       "       [0.10395814, 0.89604186],\n",
       "       [0.93863961, 0.06136039],\n",
       "       [0.76630578, 0.23369422],\n",
       "       [0.64995654, 0.35004346],\n",
       "       [0.40308415, 0.59691585],\n",
       "       [0.89879487, 0.10120513],\n",
       "       [0.89686115, 0.10313885],\n",
       "       [0.8730214 , 0.1269786 ],\n",
       "       [0.22445226, 0.77554774],\n",
       "       [0.31691535, 0.68308465],\n",
       "       [0.71373552, 0.28626448],\n",
       "       [0.57199574, 0.42800426],\n",
       "       [0.22098777, 0.77901223],\n",
       "       [0.70781837, 0.29218163],\n",
       "       [0.50131455, 0.49868545],\n",
       "       [0.84926369, 0.15073631],\n",
       "       [0.74657667, 0.25342333],\n",
       "       [0.52808069, 0.47191931],\n",
       "       [0.87324257, 0.12675743],\n",
       "       [0.95629069, 0.04370931],\n",
       "       [0.53383551, 0.46616449],\n",
       "       [0.25927707, 0.74072293],\n",
       "       [0.74099587, 0.25900413],\n",
       "       [0.08348492, 0.91651508],\n",
       "       [0.23609883, 0.76390117],\n",
       "       [0.4280415 , 0.5719585 ],\n",
       "       [0.80301027, 0.19698973],\n",
       "       [0.88070431, 0.11929569],\n",
       "       [0.30362658, 0.69637342],\n",
       "       [0.86195669, 0.13804331],\n",
       "       [0.83961818, 0.16038182],\n",
       "       [0.37219395, 0.62780605],\n",
       "       [0.99349475, 0.00650525],\n",
       "       [0.73165816, 0.26834184],\n",
       "       [0.85762208, 0.14237792],\n",
       "       [0.60847921, 0.39152079],\n",
       "       [0.60291502, 0.39708498],\n",
       "       [0.34636972, 0.65363028],\n",
       "       [0.3266232 , 0.6733768 ],\n",
       "       [0.99368402, 0.00631598],\n",
       "       [0.40383836, 0.59616164],\n",
       "       [0.47599193, 0.52400807],\n",
       "       [0.72092834, 0.27907166],\n",
       "       [0.6927339 , 0.3072661 ],\n",
       "       [0.68108552, 0.31891448],\n",
       "       [0.89298589, 0.10701411],\n",
       "       [0.83289624, 0.16710376],\n",
       "       [0.94022343, 0.05977657],\n",
       "       [0.92401377, 0.07598623],\n",
       "       [0.5585418 , 0.4414582 ],\n",
       "       [0.80444062, 0.19555938],\n",
       "       [0.93717049, 0.06282951],\n",
       "       [0.21569874, 0.78430126],\n",
       "       [0.39603832, 0.60396168],\n",
       "       [0.94970518, 0.05029482],\n",
       "       [0.86835887, 0.13164113],\n",
       "       [0.63829738, 0.36170262],\n",
       "       [0.91569922, 0.08430078],\n",
       "       [0.91182073, 0.08817927],\n",
       "       [0.89924427, 0.10075573],\n",
       "       [0.88470822, 0.11529178],\n",
       "       [0.07166909, 0.92833091],\n",
       "       [0.90422847, 0.09577153],\n",
       "       [0.75180502, 0.24819498],\n",
       "       [0.42146375, 0.57853625],\n",
       "       [0.68077568, 0.31922432],\n",
       "       [0.57728895, 0.42271105],\n",
       "       [0.71438989, 0.28561011],\n",
       "       [0.98757682, 0.01242318],\n",
       "       [0.93100851, 0.06899149],\n",
       "       [0.50739401, 0.49260599],\n",
       "       [0.6005214 , 0.3994786 ],\n",
       "       [0.82525108, 0.17474892],\n",
       "       [0.35329192, 0.64670808],\n",
       "       [0.56999144, 0.43000856],\n",
       "       [0.55477653, 0.44522347],\n",
       "       [0.94039008, 0.05960992],\n",
       "       [0.03261114, 0.96738886],\n",
       "       [0.65260412, 0.34739588],\n",
       "       [0.90197196, 0.09802804],\n",
       "       [0.96062398, 0.03937602],\n",
       "       [0.31272251, 0.68727749],\n",
       "       [0.21858222, 0.78141778],\n",
       "       [0.06378592, 0.93621408],\n",
       "       [0.08305651, 0.91694349],\n",
       "       [0.21053999, 0.78946001],\n",
       "       [0.52808559, 0.47191441],\n",
       "       [0.94058888, 0.05941112],\n",
       "       [0.99267083, 0.00732917],\n",
       "       [0.4818714 , 0.5181286 ],\n",
       "       [0.84980019, 0.15019981],\n",
       "       [0.96465316, 0.03534684],\n",
       "       [0.68522076, 0.31477924],\n",
       "       [0.11045007, 0.88954993],\n",
       "       [0.99860813, 0.00139187],\n",
       "       [0.9839931 , 0.0160069 ],\n",
       "       [0.58172452, 0.41827548],\n",
       "       [0.90545067, 0.09454933],\n",
       "       [0.96956416, 0.03043584],\n",
       "       [0.68109686, 0.31890314],\n",
       "       [0.48616398, 0.51383602],\n",
       "       [0.71947967, 0.28052033],\n",
       "       [0.977664  , 0.022336  ],\n",
       "       [0.90978657, 0.09021343],\n",
       "       [0.44825608, 0.55174392],\n",
       "       [0.82664701, 0.17335299],\n",
       "       [0.74785548, 0.25214452],\n",
       "       [0.53151626, 0.46848374],\n",
       "       [0.93183806, 0.06816194],\n",
       "       [0.8376496 , 0.1623504 ],\n",
       "       [0.90426888, 0.09573112],\n",
       "       [0.65447254, 0.34552746],\n",
       "       [0.99268946, 0.00731054],\n",
       "       [0.3747871 , 0.6252129 ],\n",
       "       [0.40567988, 0.59432012],\n",
       "       [0.86636496, 0.13363504],\n",
       "       [0.91838883, 0.08161117],\n",
       "       [0.19051741, 0.80948259],\n",
       "       [0.5797388 , 0.4202612 ],\n",
       "       [0.96054919, 0.03945081],\n",
       "       [0.71490045, 0.28509955],\n",
       "       [0.60023013, 0.39976987],\n",
       "       [0.97032285, 0.02967715],\n",
       "       [0.57182491, 0.42817509],\n",
       "       [0.77396503, 0.22603497],\n",
       "       [0.74499758, 0.25500242],\n",
       "       [0.76685722, 0.23314278],\n",
       "       [0.86379809, 0.13620191],\n",
       "       [0.65014742, 0.34985258],\n",
       "       [0.774465  , 0.225535  ],\n",
       "       [0.98338066, 0.01661934],\n",
       "       [0.85632084, 0.14367916],\n",
       "       [0.98466487, 0.01533513],\n",
       "       [0.77201635, 0.22798365],\n",
       "       [0.98873175, 0.01126825],\n",
       "       [0.98942503, 0.01057497],\n",
       "       [0.79928879, 0.20071121],\n",
       "       [0.43667761, 0.56332239],\n",
       "       [0.90632354, 0.09367646],\n",
       "       [0.89439174, 0.10560826],\n",
       "       [0.99339153, 0.00660847],\n",
       "       [0.81569672, 0.18430328],\n",
       "       [0.93150756, 0.06849244],\n",
       "       [0.97224152, 0.02775848],\n",
       "       [0.46590655, 0.53409345],\n",
       "       [0.89653487, 0.10346513],\n",
       "       [0.84341471, 0.15658529],\n",
       "       [0.93731286, 0.06268714],\n",
       "       [0.96070029, 0.03929971],\n",
       "       [0.44468936, 0.55531064],\n",
       "       [0.29444632, 0.70555368],\n",
       "       [0.60835269, 0.39164731],\n",
       "       [0.97229424, 0.02770576],\n",
       "       [0.18113624, 0.81886376],\n",
       "       [0.29478047, 0.70521953],\n",
       "       [0.63545662, 0.36454338],\n",
       "       [0.92982061, 0.07017939],\n",
       "       [0.95319465, 0.04680535],\n",
       "       [0.91639718, 0.08360282],\n",
       "       [0.08093364, 0.91906636],\n",
       "       [0.18131249, 0.81868751],\n",
       "       [0.32766015, 0.67233985],\n",
       "       [0.52880218, 0.47119782],\n",
       "       [0.14158245, 0.85841755],\n",
       "       [0.69995249, 0.30004751],\n",
       "       [0.41752884, 0.58247116],\n",
       "       [0.8965327 , 0.1034673 ]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logistic = linear_model.LogisticRegression(C=1, class_weight={1:0.4, 0:0.6}, penalty='l1', random_state=1, solver='saga')\n",
    "logistic.fit(X_train, y_train)\n",
    "y_predict=logistic.predict_proba(X_test)\n",
    "y_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss=ss.drop('Attrition',axis=1)\n",
    "ss['Attrition']=y_predict[:,1]\n",
    "ss.to_csv('submission_1.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score:  0.8486958737816159\n",
      "Best Parameters:  {'solver': 'saga', 'random_state': 1, 'penalty': 'l1', 'class_weight': {1: 0.4, 0: 0.6}, 'C': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  43 out of  50 | elapsed:    0.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:    0.2s finished\n"
     ]
    }
   ],
   "source": [
    "\"\"\"random = RCV(estimator=logistic, param_distributions=params_grid, scoring='roc_auc', cv=5, n_jobs=-1, verbose=1)\n",
    "random_result = random.fit(X_train, y_train)\n",
    "print('Best Score: ', random_result.best_score_)\n",
    "print('Best Parameters: ', random_result.best_params_)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1000 candidates, totalling 5000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  71 tasks      | elapsed:    2.8s\n",
      "[Parallel(n_jobs=-1)]: Done 1260 tasks      | elapsed:   12.0s\n",
      "[Parallel(n_jobs=-1)]: Done 3260 tasks      | elapsed:   29.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score:  0.8491113492093403\n",
      "Best Params:  {'random_state': None, 'penalty': 'elasticnet', 'loss': 'log', 'learning_rate': 'adaptive', 'eta0': 10, 'class_weight': {1: 0.4, 0: 0.6}, 'alpha': 0.001}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 5000 out of 5000 | elapsed:   42.7s finished\n"
     ]
    }
   ],
   "source": [
    "loss = ['hinge', 'log', 'modified_huber', 'squared_hinge', 'perceptron']\n",
    "penalty = ['l1', 'l2', 'elasticnet']\n",
    "alpha = [0.0001, 0.001, 0.01, 0.1, 1, 10, 100, 1000]\n",
    "learning_rate = ['constant', 'optimal', 'invscaling', 'adaptive']\n",
    "class_weight = [{1:0.5, 0:0.5}, {1:0.4, 0:0.6}, {1:0.6, 0:0.4}, {1:0.7, 0:0.3}]\n",
    "eta0 = [1, 10, 100]\n",
    "random_state=[None, 1]\n",
    "\n",
    "param_distributions = dict(loss=loss,\n",
    "                           penalty=penalty,\n",
    "                           alpha=alpha,\n",
    "                           learning_rate=learning_rate,\n",
    "                           class_weight=class_weight,\n",
    "                           eta0=eta0,\n",
    "                           random_state=random_state)\n",
    "\n",
    "random = RCV(estimator=sgd, param_distributions=param_distributions, scoring='roc_auc', verbose=1, n_jobs=-1, n_iter=1000)\n",
    "random_result = random.fit(X_train, y_train)\n",
    "\n",
    "print('Best Score: ', random_result.best_score_)\n",
    "print('Best Params: ', random_result.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd = linear_model.SGDClassifier(random_state=None, penalty='elasticnet', loss='log', learning_rate='adaptive', eta0=10, class_weight={1: 0.4, 0: 0.6}, alpha=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd.fit(X_train, y_train)\n",
    "y_predict = sgd.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss=ss.drop('Attrition',axis=1)\n",
    "ss['Attrition']=y_predict[:,1]\n",
    "ss.to_csv('submission_2.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 160 candidates, totalling 800 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:    3.6s\n",
      "[Parallel(n_jobs=-1)]: Done 288 tasks      | elapsed:   10.0s\n",
      "[Parallel(n_jobs=-1)]: Done 658 tasks      | elapsed:  2.7min\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-6a417fcf96f2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[0mgrid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGCV\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparam_grid\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mparams_grid\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'roc_auc'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m \u001b[0mgrid_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgrid\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Best Score: '\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrid_result\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_score_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Best Parameters: '\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrid_result\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_params_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    708\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    709\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 710\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    711\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    712\u001b[0m         \u001b[1;31m# For multi-metric evaluation, store the best_index_, best_params_ and\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1149\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1150\u001b[0m         \u001b[1;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1151\u001b[1;33m         \u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1152\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1153\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[1;34m(candidate_params)\u001b[0m\n\u001b[0;32m    687\u001b[0m                                \u001b[1;32mfor\u001b[0m \u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    688\u001b[0m                                in product(candidate_params,\n\u001b[1;32m--> 689\u001b[1;33m                                           cv.split(X, y, groups)))\n\u001b[0m\u001b[0;32m    690\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    691\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1015\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1016\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1017\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1018\u001b[0m             \u001b[1;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1019\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    907\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    908\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'supports_timeout'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 909\u001b[1;33m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    910\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    911\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[1;34m(future, timeout)\u001b[0m\n\u001b[0;32m    560\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[0;32m    561\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 562\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    563\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mLokyTimeoutError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    564\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\concurrent\\futures\\_base.py\u001b[0m in \u001b[0;36mresult\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    428\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    429\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 430\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    431\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    432\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mCANCELLED\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mCANCELLED_AND_NOTIFIED\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\threading.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    294\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m    \u001b[1;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    295\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 296\u001b[1;33m                 \u001b[0mwaiter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    297\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    298\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "C = [0.0001, 0.001, 0.01, 0.1, 1, 10, 100, 1000]\n",
    "kernel = ['linear']\n",
    "gamma = ['scale', 'auto']\n",
    "class_weight = [{1:0.5, 0:0.5}, {1:0.6, 0:0.4}, {1:0.4, 0:0.6}, {1:0.7, 0:0.3}, {1:0.3, 0:0.7}]\n",
    "random_state=[None, 1]\n",
    "\n",
    "params_grid = dict(C=C,\n",
    "                   class_weight=class_weight,\n",
    "                   kernel=kernel,\n",
    "                   gamma=gamma,\n",
    "                   random_state=random_state)\n",
    "grid = GCV(estimator=sv, param_grid=params_grid, scoring='roc_auc', cv=5, n_jobs=-1, verbose=1 )\n",
    "\n",
    "grid_result = grid.fit(X_train, y_train)\n",
    "print('Best Score: ', grid_result.best_score_)\n",
    "print('Best Parameters: ', grid_result.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "sv = SVC(C=100, class_weight={1: 0.5, 0: 0.5}, gamma='scale', kernel='rbf', probability=False)\n",
    "sv.fit(X_train, y_train)\n",
    "y_predict = sv.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss=ss.drop('Attrition',axis=1)\n",
    "ss['Attrition']=y_predict\n",
    "ss.to_csv('submission_1.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1,\n",
       "       0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
       "       0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
       "       0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "       0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "       0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "       1, 0, 0, 0, 1, 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
